{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"‚úì Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load training data\n",
        "with open('data/train.json', 'r', encoding='utf-8') as f:\n",
        "    resumes_data = json.load(f)\n",
        "\n",
        "print(f\"‚úì Loaded {len(resumes_data)} resumes\")\n",
        "print(f\"‚úì Ready for training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"[1/5] Extracting skills from dataset...\")\n",
        "\n",
        "extracted_skills = []\n",
        "\n",
        "for resume in resumes_data:\n",
        "    text = resume.get('text', '')\n",
        "    annotations = resume.get('annotations', [])\n",
        "    \n",
        "    for ann in annotations:\n",
        "        if len(ann) >= 3 and ann[2] == 'SKILL':\n",
        "            start, end = ann[0], ann[1]\n",
        "            skill_text = text[start:end].strip().lower()\n",
        "            if skill_text and len(skill_text) > 1:\n",
        "                extracted_skills.append(skill_text)\n",
        "\n",
        "# Get unique skills\n",
        "unique_extracted_skills = sorted(set(extracted_skills))\n",
        "\n",
        "print(f\"‚úì Extracted {len(extracted_skills)} total skill mentions\")\n",
        "print(f\"‚úì Found {len(unique_extracted_skills)} unique skills\")\n",
        "print(f\"\\nSample skills: {unique_extracted_skills[:20]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"[2/5] Building comprehensive skill database...\")\n",
        "\n",
        "# Manual list of important tech skills\n",
        "manual_tech_skills = [\n",
        "    # Programming Languages\n",
        "    'python', 'java', 'javascript', 'c++', 'c#', 'ruby', 'php', 'swift',\n",
        "    'kotlin', 'go', 'rust', 'typescript', 'scala', 'r', 'matlab', 'perl',\n",
        "    \n",
        "    # Web Technologies\n",
        "    'html', 'css', 'react', 'angular', 'vue', 'nodejs', 'django', 'flask',\n",
        "    'spring', 'express', 'jquery', 'bootstrap', 'tailwind',\n",
        "    \n",
        "    # Databases\n",
        "    'sql', 'mysql', 'postgresql', 'mongodb', 'oracle', 'redis', 'cassandra',\n",
        "    'sqlite', 'mariadb', 'dynamodb', 'elasticsearch',\n",
        "    \n",
        "    # Cloud & DevOps\n",
        "    'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', 'terraform',\n",
        "    'ansible', 'ci/cd', 'travis ci', 'circleci', 'gitlab',\n",
        "    \n",
        "    # Data Science & ML\n",
        "    'machine learning', 'deep learning', 'data analysis', 'pandas', 'numpy',\n",
        "    'tensorflow', 'pytorch', 'scikit-learn', 'keras', 'opencv',\n",
        "    'tableau', 'power bi', 'spark', 'hadoop',\n",
        "    \n",
        "    # Tools & Methodologies\n",
        "    'git', 'github', 'jira', 'confluence', 'linux', 'unix', 'agile',\n",
        "    'scrum', 'rest api', 'graphql', 'microservices', 'testing'\n",
        "]\n",
        "\n",
        "# Combine extracted and manual skills\n",
        "complete_skill_database = sorted(set(unique_extracted_skills + manual_tech_skills))\n",
        "\n",
        "print(f\"‚úì Manual skills added: {len(manual_tech_skills)}\")\n",
        "print(f\"‚úì Total unique skills in database: {len(complete_skill_database)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"[3/5] Training TF-IDF vectorizer...\")\n",
        "\n",
        "# Extract all resume texts\n",
        "resume_texts = [resume.get('text', '') for resume in resumes_data]\n",
        "\n",
        "# Initialize and train TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words='english',       \n",
        "    ngram_range=(1, 2),         \n",
        "    max_features=1000,        \n",
        "    min_df=2,                  \n",
        "    max_df=0.8                \n",
        ")\n",
        "\n",
        "# Fit the vectorizer on resume texts\n",
        "vectorizer.fit(resume_texts)\n",
        "\n",
        "print(f\"‚úì TF-IDF vectorizer trained on {len(resume_texts)} resumes\")\n",
        "print(f\"‚úì Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
        "print(f\"\\nTop 20 TF-IDF terms: {list(vectorizer.vocabulary_.keys())[:20]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"[4/5] Saving trained models...\")\n",
        "\n",
        "# Create models directory\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Package everything together\n",
        "model_package = {\n",
        "    'vectorizer': vectorizer,\n",
        "    'skill_database': complete_skill_database,\n",
        "    'training_stats': {\n",
        "        'total_resumes': len(resumes_data),\n",
        "        'total_skills': len(complete_skill_database),\n",
        "        'extracted_skills': len(unique_extracted_skills),\n",
        "        'manual_skills': len(manual_tech_skills),\n",
        "        'vocabulary_size': len(vectorizer.vocabulary_)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save using pickle\n",
        "with open('models/resume_scanner_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model_package, f)\n",
        "\n",
        "print(\"‚úì Model saved to: models/resume_scanner_model.pkl\")\n",
        "print(f\"‚úì File size: {os.path.getsize('models/resume_scanner_model.pkl') / 1024:.2f} KB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"[5/5] Saving skill database...\")\n",
        "\n",
        "# Save skill database\n",
        "with open('models/skill_database.txt', 'w', encoding='utf-8') as f:\n",
        "    f.write(\"COMPLETE SKILL DATABASE\\n\")\n",
        "    f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "    for i, skill in enumerate(complete_skill_database, 1):\n",
        "        f.write(f\"{i:4d}. {skill}\\n\")\n",
        "\n",
        "print(\"‚úì Skill database saved to: models/skill_database.txt\")\n",
        "\n",
        "# Also save as JSON\n",
        "with open('models/skill_database.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(complete_skill_database, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"‚úì Skill database saved to: models/skill_database.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Verifying model loading...\")\n",
        "\n",
        "# Try to load the model\n",
        "with open('models/resume_scanner_model.pkl', 'rb') as f:\n",
        "    loaded_model = pickle.load(f)\n",
        "\n",
        "print(\"‚úì Model loaded successfully!\")\n",
        "print(\"\\nModel contents:\")\n",
        "print(f\"  - Vectorizer: {type(loaded_model['vectorizer']).__name__}\")\n",
        "print(f\"  - Skills in database: {len(loaded_model['skill_database'])}\")\n",
        "print(f\"  - Training stats: {loaded_model['training_stats']}\")\n",
        "\n",
        "# Test vectorizer\n",
        "test_text = \"Python developer with 5 years experience in machine learning and AWS\"\n",
        "test_vector = loaded_model['vectorizer'].transform([test_text])\n",
        "print(f\"\\n‚úì Vectorizer test passed! Shape: {test_vector.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"TRAINING COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "stats = loaded_model['training_stats']\n",
        "\n",
        "print(f\"\\nüìä TRAINING STATISTICS\")\n",
        "print(f\"  Total Resumes Processed: {stats['total_resumes']:,}\")\n",
        "print(f\"  Skills Extracted from Data: {stats['extracted_skills']:,}\")\n",
        "print(f\"  Manual Skills Added: {stats['manual_skills']:,}\")\n",
        "print(f\"  Total Skills in Database: {stats['total_skills']:,}\")\n",
        "print(f\"  TF-IDF Vocabulary Size: {stats['vocabulary_size']:,}\")\n",
        "\n",
        "print(f\"\\nüìÅ OUTPUT FILES\")\n",
        "print(f\"  ‚úì models/resume_scanner_model.pkl\")\n",
        "print(f\"  ‚úì models/skill_database.txt\")\n",
        "print(f\"  ‚úì models/skill_database.json\")\n",
        "\n",
        "print(f\"\\nüéØ WHAT THIS MODEL CAN DO\")\n",
        "print(f\"  ‚úì Extract skills from any resume\")\n",
        "print(f\"  ‚úì Calculate text similarity with job descriptions\")\n",
        "print(f\"  ‚úì Match resume skills with job requirements\")\n",
        "print(f\"  ‚úì Generate ATS compatibility scores\")\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 70)\n",
        "print(\"Next: Run notebook '03_Resume_Analyzer.ipynb' to use the model!\")\n",
        "print(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
